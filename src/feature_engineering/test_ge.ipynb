{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f3b4838-2990-4815-92aa-0f848fd93c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "require('data.table')\n",
    "require('lightgbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eadda77-5f04-41c6-9765-01d426894eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset <- fread(\"~/OneDrive/0.ITBA/Mineria_de_datos/dm2025a/src/GFE_Sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecf27b-b33d-4209-921a-65baedc7c7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ccd311e-591d-4e4b-b981-06bc60dc7515",
   "metadata": {
    "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1"
   },
   "source": [
    "### 9.7.2 Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb7fe5-b247-4cca-9433-deb25e84330a",
   "metadata": {
    "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157"
   },
   "source": [
    "#### 9.7.2.1 Training Strategy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26739a70-8c29-412e-a37a-f8e7209ff176",
   "metadata": {
    "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1"
   },
   "source": [
    "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
    "\n",
    "* future = 202109  obviamente completo\n",
    "\n",
    "* final_train =  [ 201901, 202107 ] sin undersampling de los CONTINUA\n",
    "\n",
    "* training\n",
    "   * testing = NO HAY\n",
    "   * validation =  202107   completo, sin undersampling\n",
    "   * training = [ 201901, 202105 ]  donde se consideran el 20% de los CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88839037-da8a-4163-bb70-a9baf87f3db5",
   "metadata": {
    "id": "2c9c0a42-ba58-4264-8566-091a6161716f"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$semilla_primigenia <- 106109\n",
    "\n",
    "PARAM$experimento <- \"FE_test\"\n",
    "PARAM$trainingstrategy$validate <- c(202107)\n",
    "\n",
    "PARAM$trainingstrategy$training <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104, 202105\n",
    ")\n",
    "\n",
    "PARAM$trainingstrategy$training_pct <- 0.2\n",
    "\n",
    "\n",
    "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46743b3e-3c2b-4db4-a2a3-1b78eb0e3a75",
   "metadata": {
    "id": "tv_trHWAj4a8"
   },
   "outputs": [],
   "source": [
    "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
    "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e6ce2b8-1955-4c69-a490-1f14dda321a8",
   "metadata": {
    "id": "Ud_XDKSIj8f_"
   },
   "outputs": [],
   "source": [
    "# los campos en los que se entrena\n",
    "campos_buenos <- copy( setdiff(\n",
    "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "240c0c8f-c433-421d-b82e-5e4c2191cc5e",
   "metadata": {
    "id": "rFKgZZPSj_Pa"
   },
   "outputs": [],
   "source": [
    "# preparo para que se puede hacer undersampling de los CONTINUA\n",
    "#  solamente por un tema de VELOCIDAD\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar:=runif(nrow(dataset))]\n",
    "\n",
    "# undersampling de los CONTINUA\n",
    "dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
    "    (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
    "     azar < PARAM$trainingstrategy$training_pct ) ]\n",
    "\n",
    "\n",
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
    "  label= dataset[fold_train == TRUE, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56115d37-b38a-4abd-aaa4-33bef8e3b97c",
   "metadata": {
    "id": "B3yo98kQkHcP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "29"
      ],
      "text/latex": [
       "29"
      ],
      "text/markdown": [
       "29"
      ],
      "text/plain": [
       "[1] 29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datos de validation\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
    "  label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "nrow(dvalidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6042a72-2b62-4165-9d1a-0db5cc484aec",
   "metadata": {
    "id": "28e8f788-551c-4e50-9029-302ac0834287"
   },
   "source": [
    "####  9.7.2.2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff0e90-7145-4733-bd47-bc86b1b5931c",
   "metadata": {
    "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7"
   },
   "source": [
    "* Clase binaria que se optimiza :  positivos = [ BAJA+1, BAJA+2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10a75b-3281-4e30-b592-64f99672883f",
   "metadata": {
    "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb"
   },
   "source": [
    "* Metrica que se optimiza **AUC** Area Under Curve de la  ROC Curve\n",
    "\n",
    "es muy importante notar que intencionalmente  **NO** se está optimizando la funcion de ganancia del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b46c73-86ad-42c8-9860-20d1449db43f",
   "metadata": {
    "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704"
   },
   "source": [
    "* Cantidad de iteraciones inteligentes de la Optimizacion Bayesiana = **10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f725e08-4029-4bae-b1a6-dbce1cb16c2f",
   "metadata": {
    "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a"
   },
   "source": [
    "* Parametros no default, fijos de LightGBM que no se optimizan\n",
    "  * max_bin = 31 , Alienigenas Ancestrales contruyeron las pirámides y dejaron a la humanidad en un jeroglifico  *max_bin=31*\n",
    "  * feature_fraction = 0.5  para poner algo que generalmente no falla\n",
    "  * learning_rate = 0.03  para que aprenda lento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c97f5-6db2-46de-9203-87a24cfc6c42",
   "metadata": {
    "id": "1e7da08e-fe57-4681-beff-11fe963116bd"
   },
   "source": [
    "* Parametros que se optimizan en la Bayesian Optimization\n",
    "  * num_leaves  [8, 256]\n",
    "  * min_data_in_leaf  [8, 8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89941b98-0f77-40d3-a37f-ec9a6516164e",
   "metadata": {
    "id": "34V6y4GetKq_"
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371b3aa-738a-4fdd-8756-25b3eb61bff9",
   "metadata": {
    "id": "UFbDSYtH0TTT"
   },
   "source": [
    "Definición de la Bayesian Optimization\n",
    "<br> Si se desea optimizar un hiperparámetro que esta como fijo, debe QUITARSE de param_fijos y agregarse a PARAM$hipeparametertuning$hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4a54f-8ae3-477d-a09b-4c75af14f4dd",
   "metadata": {
    "id": "5Uag3XGHqrfZ"
   },
   "outputs": [],
   "source": [
    "# 40 es el minimo razonable,  un buen analista Sr aumentara este valor\n",
    "PARAM$hipeparametertuning$num_interations <- 40\n",
    "\n",
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  extra_trees = FALSE,\n",
    "\n",
    "  max_depth = -1L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "  min_gain_to_split = 0.0, # min_gain_to_split >= 0.0\n",
    "  min_sum_hessian_in_leaf = 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
    "  lambda_l1 = 0.0, # lambda_l1 >= 0.0\n",
    "  lambda_l2 = 0.0, # lambda_l2 >= 0.0\n",
    "\n",
    "  bagging_fraction = 1.0, # 0.0 < bagging_fraction <= 1.0\n",
    "  pos_bagging_fraction = 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
    "  neg_bagging_fraction = 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  is_unbalance = FALSE, #\n",
    "  scale_pos_weight = 1.0, # scale_pos_weight > 0.0\n",
    "\n",
    "  drop_rate = 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
    "  max_drop = 50, # <=0 means no limit\n",
    "  skip_drop = 0.5, # 0.0 <= skip_drop <= 1.0\n",
    "\n",
    "  max_bin= 31,\n",
    "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
    "  early_stopping_rounds= 200\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22bf9b-9bf6-4157-bd28-24d95766bbda",
   "metadata": {
    "id": "0M2oWhHxHc-9"
   },
   "source": [
    "Nuevos  pseudo hiperparámetros\n",
    "\n",
    "*   leaf_size (0.0,  0.5]  es el   min_data_in_leaf / nrow(dataset)\n",
    "*   coverage (0.0, 1.0]  se cumple   num_leaves =   coverage * (nrow(dataset)/min_data_in_leaf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc00540c-1e82-400c-8479-0b176d82482f",
   "metadata": {
    "id": "ysYzPjs3CT_a"
   },
   "outputs": [],
   "source": [
    "# Notar que se usan los pseudo hiperparametros \"ratio\"  leaf_size  y coverage\n",
    "#  que luego terminan en  min_data_in_leaf y  num_leaves\n",
    "#  de forma que sea invariante al tamaño del dataset\n",
    "\n",
    "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower = 0.02, upper = 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower = 0.05, upper = 0.90),\n",
    "  makeNumericParam(\"coverage\", lower = 0.05, upper = 1.0), # nuevo\n",
    "  makeNumericParam(\"leaf_size\", lower = 0.001, upper = 0.2) # nuevo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1114ea01-e9c5-4eee-b2a7-20d21e245528",
   "metadata": {
    "id": "FEa1UuuAz4yj"
   },
   "source": [
    "Función \"señora caja negra\"  que es llamada para verificar la realidad por la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2b49b-e0f2-432d-acd6-2632096955f2",
   "metadata": {
    "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2"
   },
   "outputs": [],
   "source": [
    "# En  x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en validate del modelo entrenado\n",
    "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  # x pisa (o agrega) a param_fijos\n",
    "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # hago la transformacion de leaf_size y  coverage\n",
    "  if( \"leaf_size\"  %in% names(param_completo) &\n",
    "      \"coverage\"  %in% names(param_completo)\n",
    "  )\n",
    "  {\n",
    "    # primero defino el tamaño de las hojas\n",
    "    param_completo$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_completo$leaf_size )  )\n",
    "    # luego la cantidad de hojas en funcion del valor anterior, el coverage, y la cantidad de registros\n",
    "    param_completo$num_leaves <- pmin( 131072,\n",
    "      pmax( 8,  round( ( param_completo$coverage * nrow( dtrain ) / param_completo$min_data_in_leaf ) ) ))\n",
    "  }\n",
    "\n",
    "  if( \"leaf_size\"  %in% names(param_completo) &\n",
    "      !( \"coverage\"  %in% names(param_completo) )\n",
    "  )\n",
    "  {\n",
    "    # primero defino el tamaño de las hojas\n",
    "    param_completo$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_completo$leaf_size )  )\n",
    "  }\n",
    "\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelo_train <- lgb.train(\n",
    "    data= dtrain,\n",
    "    valids= list(valid = dvalidate),\n",
    "    eval= \"auc\",\n",
    "    param= param_completo,\n",
    "    verbose= -100\n",
    "  )\n",
    "\n",
    "  # recupero la AUC en validation\n",
    "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
    "\n",
    "  # esta es la forma de devolver un parametro extra\n",
    "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelo_train)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97868efc-910e-42e7-8415-ebae4dc33c7d",
   "metadata": {
    "id": "267a35d4-adaf-4271-a875-3864111333b7"
   },
   "source": [
    "seteo de la Bayesian Optimization (complejo)\n",
    "<br> copiado y pegado de la documentación de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f828a7-315e-44a4-9034-137d0db0c816",
   "metadata": {
    "id": "43c2a92d-1041-46b8-bff2-47297f209ed2"
   },
   "outputs": [],
   "source": [
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "    fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
    "    minimize= FALSE, # estoy Maximizando AUC\n",
    "    noisy= FALSE,\n",
    "    par.set= PARAM$hipeparametertuning$hs,\n",
    "    has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "    save.on.disk.at.time= 600,\n",
    "    save.file.path= \"HT.RDATA\"\n",
    ")\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "    ctrl,\n",
    "    iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
    ")\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales\n",
    "#   los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "# mas configuraciones\n",
    "surr.km <- makeLearner(\n",
    "    \"regr.km\",\n",
    "    predict.type= \"se\",\n",
    "    covtype= \"matern3_2\",\n",
    "    control= list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbbdbd7-6292-4f39-9ae6-8c14bac7966a",
   "metadata": {
    "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8"
   },
   "source": [
    "Corrida de la Bayesian Optimization,  aqui se hace el trabajo pesado\n",
    "<br> por favor no se asuste con los warnings que pudieran aparecer\n",
    "\n",
    "Si corrío a medias y llegó a las iteraciones inteligentes, en el archivo binario HT.RDATA quedó lo ya procesado y es utilizado para retomar la corrida desde lo último que llegó a grabar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92889634-b6a3-402c-a002-f591a3b1e965",
   "metadata": {
    "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "\n",
    "if (!file.exists(\"HT.RDATA\")) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(\"HT.RDATA\") # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f05e5-519f-4f3b-98ab-c52d8c9a6cfe",
   "metadata": {
    "id": "36307612-964f-4df3-907a-1bc3c095f178"
   },
   "source": [
    "la bayesian optimization ha corrido, extraigo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9c9d8-f16d-4ae1-9136-06d9b0dde2b0",
   "metadata": {
    "id": "8c061a2a-3341-4006-a154-c95bb6cfd407"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y, -num_iterations)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file=\"BO_log.txt\",\n",
    "  sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  list(learning_rate, feature_fraction, coverage, leaf_size)\n",
    "]\n",
    "\n",
    "print(PARAM$out$lgbm$mejores_hiperparametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8198c-6fd0-4957-918e-c9a69ded121e",
   "metadata": {
    "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc"
   },
   "source": [
    "### 9.7.3 Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d6132-b74e-408e-87dd-5da38bdb1f3f",
   "metadata": {
    "id": "c39492c3-756f-47a5-8747-93ade8275306"
   },
   "source": [
    "#### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f913302-0d69-47d6-8393-cc69ef83e5a2",
   "metadata": {
    "id": "xhKi_G_sYQqq"
   },
   "source": [
    "##### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a31821-f77a-459f-b3da-7302d90503f3",
   "metadata": {
    "id": "qyHfS_X0zd7o"
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$final_train <- c(\n",
    "  201901, 201902, 201903, 201904, 201905, 201906,\n",
    "  201907, 201908, 201909, 201910, 201911, 201912,\n",
    "  202001, 202002, 202003, 202004, 202005, 202006,\n",
    "  202007, 202008, 202009, 202010, 202011, 202012,\n",
    "  202101, 202102, 202103, 202104, 202105, 202106,\n",
    "  202107\n",
    ")\n",
    "\n",
    "dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
    "\n",
    "# creo el dfinal_train en formato  LightGBM\n",
    "dfinal_train <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
    "  label= dataset[fold_final_train == TRUE, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "nrow( dfinal_train) # verifico el tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953a946-8138-4c7c-802c-6888a629cec0",
   "metadata": {
    "id": "HATRyklxYUpT"
   },
   "source": [
    "##### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51fb6a-b910-4a5c-a31d-d91f18c87562",
   "metadata": {
    "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01"
   },
   "outputs": [],
   "source": [
    "# uno los parametros fijos y los mejores encontrados de los variables\n",
    "fijos <- copy(PARAM$lgbm$param_fijos)\n",
    "\n",
    "# quito lo que optimice en la Bayesian Optimization\n",
    "fijos$num_iterations <- NULL\n",
    "fijos$early_stopping_rounds <- NULL\n",
    "\n",
    "# agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
    "param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)\n",
    "\n",
    "# hago la transformacion de leaf_size y  coverage\n",
    "  if( \"leaf_size\"  %in% names(param_final) &\n",
    "      \"coverage\"  %in% names(param_final)\n",
    "  )\n",
    "  {\n",
    "    # primero defino el tamaño de las hojas\n",
    "    param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
    "    # luego la cantidad de hojas en funcion del valor anterior, el coverage, y la cantidad de registros\n",
    "    param_final$num_leaves <- pmin( 131072,\n",
    "      pmax( 8,  round( ( param_final$coverage * nrow( dtrain ) / param_final$min_data_in_leaf ) ) ))\n",
    "  }\n",
    "\n",
    "  if( \"leaf_size\"  %in% names(param_final) &\n",
    "      !( \"coverage\"  %in% names(param_final) )\n",
    "  )\n",
    "  {\n",
    "    # primero defino el tamaño de las hojas\n",
    "    param_final$min_data_in_leaf <- pmax( 1,  round( nrow(dtrain) * param_final$leaf_size )  )\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36881f06-c82b-4f36-af9b-9da28000bc00",
   "metadata": {
    "id": "5Y2WIAWbYc1C"
   },
   "outputs": [],
   "source": [
    "param_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a376fcd-ddac-4dc7-8a64-81c186a3951e",
   "metadata": {
    "id": "05d3494f-0401-4f3e-9b69-f488a737879d"
   },
   "source": [
    "##### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875af856-cb5c-4ad8-9d8e-3ecafb77fbcb",
   "metadata": {
    "id": "HhvnAhuxdXWq"
   },
   "outputs": [],
   "source": [
    "PARAM$FT$semillerio <- 20  # cantidad de semillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca904313-8445-40d7-a937-fb5899746fb0",
   "metadata": {
    "id": "tcYH_MiJdeEs"
   },
   "outputs": [],
   "source": [
    "if(!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6309b27-7dd3-4ca1-a97c-3d6e6269624c",
   "metadata": {
    "id": "weEzmJf5fiog"
   },
   "outputs": [],
   "source": [
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "# me quedo con PARAM$semillerio  primos al azar\n",
    "PARAM$FT$semillas <- sample(primos)[seq(PARAM$FT$semillerio)]\n",
    "\n",
    "cat( PARAM$FT$semillas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066be747-847d-45d9-a2f1-5e35fa48db0d",
   "metadata": {
    "id": "fa239848-1c28-4ee5-984a-073903b4b279"
   },
   "outputs": [],
   "source": [
    "dir.create(\"modelos\", showWarnings =FALSE)\n",
    "\n",
    "primero <- TRUE\n",
    "for( sem in PARAM$FT$semillas)\n",
    "{\n",
    "  nombre_arch <- paste0( \"./modelos/modelo_\", sem, \".txt\")\n",
    "  if( !file.exists(nombre_arch) )\n",
    "  {\n",
    "    param_final$seed <- sem\n",
    "\n",
    "    set.seed(sem, kind = \"L'Ecuyer-CMRG\")\n",
    "    final_model <- lgb.train(\n",
    "      data= dfinal_train,\n",
    "      param= param_final,\n",
    "      verbose= -100\n",
    "    )\n",
    "\n",
    "    lgb.save(final_model, nombre_arch) # grabo el modelo\"\n",
    "\n",
    "    # grabo la primer importancia de variables\n",
    "    #  Natalia : da lo mismo cual se guarda\n",
    "    if( primero)\n",
    "    {\n",
    "      primero <- FALSE\n",
    "      tb_importancia <- as.data.table(lgb.importance(final_model))\n",
    "      archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "      fwrite( tb_importancia,\n",
    "        file= archivo_importancia,\n",
    "        sep= \"\\t\"\n",
    "      )\n",
    "    }\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c5ad9-db8b-421e-a915-3cf0b1e02498",
   "metadata": {
    "id": "7ea225b3-ce02-42e2-8330-b10ed250d172"
   },
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2dbec2-6117-4d6e-89cb-bc294598a244",
   "metadata": {
    "id": "164981bb-f4c1-4228-8bc9-32e58a383c05"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e0171-c212-47b2-9081-ff0b5e0659ce",
   "metadata": {
    "id": "eJ7RbT271v-R"
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$future <- c(202109)\n",
    "\n",
    "dfuture <- dataset[ foto_mes %in% PARAM$trainingstrategy$future ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3399e4-a82b-4068-94c4-c88661ec497e",
   "metadata": {
    "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f"
   },
   "outputs": [],
   "source": [
    "# aplico final_model   a dfuture\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := 0]\n",
    "\n",
    "datos_matrix <- data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    "\n",
    "\n",
    "for( isem in seq(length(PARAM$FT$semillas)) )\n",
    "{\n",
    "   sem <- PARAM$FT$semillas[ isem ]\n",
    "   nombre_arch <- paste0( \"./modelos/modelo_\", sem, \".txt\")\n",
    "   final_model <- lgb.load(nombre_arch)\n",
    "\n",
    "   prediccion <- predict(\n",
    "     final_model,\n",
    "     datos_matrix\n",
    "  )\n",
    "\n",
    "  tb_prediccion[, paste0(\"prob_\", isem) := prediccion]\n",
    "  tb_prediccion[, prob := prob + prediccion]\n",
    "\n",
    "  rm(final_model)\n",
    "  rm(prediccion)\n",
    "  gc(full = TRUE, verbose=FALSE)\n",
    "}\n",
    "\n",
    "rm( datos_matrix)\n",
    "gc(full = TRUE, verbose=FALSE)\n",
    "\n",
    "tb_prediccion[, prob := prob /length(PARAM$FT$semillas) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58bd8c-201f-4601-8523-98c86e67d01e",
   "metadata": {
    "id": "Q10qYVKNqqte"
   },
   "outputs": [],
   "source": [
    "# veo que hay en tb_prediccion\n",
    "tb_prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9d410-1179-4e08-b6d9-b12a67a218cc",
   "metadata": {
    "id": "TB6aerGDZeTo"
   },
   "outputs": [],
   "source": [
    "# grabo las probabilidad del modelo\n",
    "#  me va a ser util para hacer Ensembles de modelos\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96323f21-0c1f-4204-bd70-dd81df23da35",
   "metadata": {
    "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50"
   },
   "source": [
    "#### Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5318475-8519-4090-95b7-2c6e3cc3bb92",
   "metadata": {
    "id": "55970cb6-856a-46e3-a893-7f36b8352b8e"
   },
   "source": [
    "Genero las salidas y hago los submits a Kaggles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74e5dc-06ee-4706-a0f6-409e41dc3034",
   "metadata": {
    "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-a\"\n",
    "PARAM$kaggle$cortes <- seq(10000, 12000, by = 500)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\n",
    "    \"./kaggle/KA\",\n",
    "    PARAM$experimento, \"_\",\n",
    "    \"s\", length(PARAM$FT$semillas), \"_\",\n",
    "    envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c026e-e7d2-4c3b-bd32-0f6b456bd68b",
   "metadata": {
    "id": "C94tK-xid6p2"
   },
   "outputs": [],
   "source": [
    "# grabo los parametros\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0eb01-09df-4d97-8be1-838ce9d1eb2a",
   "metadata": {
    "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa8b33-9fbc-44ea-b8ba-4c69c257fbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79c1a4-3a1e-447d-b9e0-1e33e3a222e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1dde93-6b9d-4211-a0b2-c0e4ac8b54a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52e03f-255e-4f51-a127-43cbda8d3656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2483ed9d-8a4c-4233-bcd1-ba0dadbc6e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc4557-05c6-4a93-93a9-8ab19208053f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ea3b4-ad91-483b-b972-38aa06895f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49128b8-57a6-4233-93ca-1a968f341bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65608ab-f140-42fd-b730-b252ac91ab1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfded8a-42c6-4c94-95e2-27684d8642af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ab955-9ee5-4ad3-8a50-9ea596380e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d980549-ef81-43c7-8127-ee72bf03bf70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c59a1-5d1e-43d6-a436-8a9fe5391cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6278cfe-09e4-46c8-98a6-98e0d20b6043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c1948-192d-4804-a217-cc42be630ce7",
   "metadata": {
    "id": "Vd09ZaybfUeK",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27d85d-f72a-47da-967c-9ac88502e57e",
   "metadata": {
    "id": "JrsaXcQqcefM",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "AgregaVarRandomForest <- function() {\n",
    "\n",
    "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
    "  gc(verbose= FALSE)\n",
    "  dataset[, clase01 := 0L ]\n",
    "  dataset[ clase_ternaria %in% PARAM$FE_rf$train$clase01_valor1,\n",
    "      clase01 := 1L ]\n",
    "\n",
    "  campos_buenos <- setdiff(\n",
    "    colnames(dataset),\n",
    "    c( \"clase_ternaria\", \"clase01\")\n",
    "  )\n",
    "\n",
    "  dataset[, entrenamiento :=\n",
    "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
    "\n",
    "  dtrain <- lgb.Dataset(\n",
    "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
    "    label = dataset[entrenamiento == TRUE, clase01],\n",
    "    free_raw_data = FALSE\n",
    "  )\n",
    "\n",
    "  modelo <- lgb.train(\n",
    "     data = dtrain,\n",
    "     param = PARAM$FE_rf$lgb_param,\n",
    "     verbose = -100\n",
    "  )\n",
    "\n",
    "  cat( \"Fin construccion RandomForest\\n\" )\n",
    "  add_log( \"Fin construccion RandomForest\\n\" )\n",
    "  # grabo el modelo, achivo .model\n",
    "  lgb.save(modelo, file=\"modelo.model\" )\n",
    "\n",
    "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
    "\n",
    "  periodos <- dataset[ , unique( foto_mes ) ]\n",
    "\n",
    "  for( periodo in  periodos )\n",
    "  {\n",
    "    cat( \"periodo = \", periodo, \"\\n\" )\n",
    "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
    "\n",
    "    cat( \"Inicio prediccion\\n\" )\n",
    "    prediccion <- predict(\n",
    "        modelo,\n",
    "        datamatrix,\n",
    "        type = \"leaf\"\n",
    "    )\n",
    "    cat( \"Fin prediccion\\n\" )\n",
    "\n",
    "    for( arbolito in 1:qarbolitos )\n",
    "    {\n",
    "       cat( arbolito, \" \" )\n",
    "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
    "\n",
    "       for (pos in 1:length(hojas_arbol)) {\n",
    "         # el numero de nodo de la hoja, estan salteados\n",
    "         nodo_id <- hojas_arbol[pos]\n",
    "         dataset[ foto_mes== periodo, paste0(\n",
    "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
    "             \"_\", sprintf(\"%03d\", nodo_id)\n",
    "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
    "\n",
    "       }\n",
    "\n",
    "       rm( hojas_arbol )\n",
    "    }\n",
    "    cat( \"\\n\" )\n",
    "\n",
    "    rm( prediccion )\n",
    "    rm( datamatrix )\n",
    "    gc(verbose= FALSE)\n",
    "  }\n",
    "\n",
    "  gc(verbose= FALSE)\n",
    "\n",
    "  # borro clase01 , no debe ensuciar el dataset\n",
    "  dataset[ , clase01 := NULL ]\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b3b47-9f12-4c75-a467-ad4c3f9847e9",
   "metadata": {
    "id": "i6vcLtXldMpz",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
    "\n",
    "# Estos CUATRO parametros son los que se deben modificar\n",
    "PARAM$FE_rf$arbolitos= 20\n",
    "PARAM$FE_rf$hojas_por_arbol= 16\n",
    "PARAM$FE_rf$datos_por_hoja= 100\n",
    "PARAM$FE_rf$mtry_ratio= 0.2\n",
    "\n",
    "# Estos son quasi fijos\n",
    "PARAM$FE_rf$train$clase01_valor1 <- c( \"BAJA+2\", \"BAJA+1\")\n",
    "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
    "\n",
    "# Estos TAMBIEN son quasi fijos\n",
    "PARAM$FE_rf$lgb_param <-list(\n",
    "    # parametros que se pueden cambiar\n",
    "    num_iterations = PARAM$FE_rf$arbolitos,\n",
    "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
    "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
    "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
    "\n",
    "    # para que LightGBM emule Random Forest\n",
    "    boosting = \"rf\",\n",
    "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
    "    bagging_freq = 1.0,\n",
    "    feature_fraction = 1.0,\n",
    "\n",
    "    # genericos de LightGBM\n",
    "    max_bin = 31L,\n",
    "    objective = \"binary\",\n",
    "    first_metric_only = TRUE,\n",
    "    boost_from_average = TRUE,\n",
    "    feature_pre_filter = FALSE,\n",
    "    force_row_wise = TRUE,\n",
    "    verbosity = -100,\n",
    "    max_depth = -1L,\n",
    "    min_gain_to_split = 0.0,\n",
    "    min_sum_hessian_in_leaf = 0.001,\n",
    "    lambda_l1 = 0.0,\n",
    "    lambda_l2 = 0.0,\n",
    "\n",
    "    pos_bagging_fraction = 1.0,\n",
    "    neg_bagging_fraction = 1.0,\n",
    "    is_unbalance = FALSE,\n",
    "    scale_pos_weight = 1.0,\n",
    "\n",
    "    drop_rate = 0.1,\n",
    "    max_drop = 50,\n",
    "    skip_drop = 0.5,\n",
    "\n",
    "    extra_trees = FALSE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468fc41-d046-4a6f-b426-f442d43c57d6",
   "metadata": {
    "id": "GTTj4VdBezcE",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering agregando variables de Random Forest\n",
    "AgregaVarRandomForest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
